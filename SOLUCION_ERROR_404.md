# üîß Soluci√≥n al Error 404 en Scraping Items

## ‚ùå Error Actual

```
GET http://localhost:8000/api/scraping-items/stats/summary 404 (Not Found)
```

## ‚úÖ Causa del Problema

El backend est√° corriendo con c√≥digo antiguo (antes de agregar las rutas de scraping). Necesita **reiniciarse** para cargar las nuevas rutas.

## üöÄ Soluci√≥n Paso a Paso

### Paso 1: Detener el Backend

Si tienes el backend corriendo en una terminal, presiona `Ctrl + C` para detenerlo.

### Paso 2: Verificar que la Tabla Existe

La tabla `scraping_items` ya fue creada correctamente. Puedes verificarlo con:

```powershell
docker exec ladatajusta-db-1 psql -U ladatajusta -d ladatajusta -c "\dt scraping_items"
```

Deber√≠as ver:
```
           List of relations
 Schema |      Name       | Type  |   Owner
--------+-----------------+-------+------------
 public | scraping_items  | table | ladatajusta
```

### Paso 3: Reiniciar el Backend

```powershell
cd backend
.\.venv\Scripts\Activate.ps1
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Deber√≠as ver en la salida:
```
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [xxxxx] using StatReload
INFO:     Started server process [xxxxx]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```

### Paso 4: Verificar que las Rutas Est√°n Cargadas

Abrir en el navegador:
```
http://localhost:8000/docs
```

Buscar la secci√≥n **"scraping-items"** - deber√≠as ver:
- `POST /api/scraping-items`
- `POST /api/scraping-items/upsert`
- `GET /api/scraping-items`
- `GET /api/scraping-items/{item_id}`
- `PATCH /api/scraping-items/{item_id}`
- `DELETE /api/scraping-items/{item_id}`
- `POST /api/scraping-items/{item_id}/publish`
- `GET /api/scraping-items/stats/summary`
- `POST /api/scraping-items/bulk/mark-duplicates`

### Paso 5: Probar el Endpoint Manualmente

En una nueva terminal PowerShell:

```powershell
curl http://localhost:8000/api/scraping-items/stats/summary
```

Deber√≠as obtener una respuesta JSON (aunque est√© vac√≠a porque no hay datos a√∫n):

```json
{
  "total_items": 0,
  "by_status": {},
  "by_source_media": {},
  "avg_ai_tokens": null,
  "total_ai_cost_usd": null,
  "items_with_errors": 0,
  "items_ready_for_ai": 0,
  "items_pending_publish": 0
}
```

### Paso 6: Crear Datos de Prueba

Ahora que el backend est√° corriendo correctamente:

```powershell
cd backend
python -m scripts.seed_scraping_items
```

Deber√≠as ver:
```
============================================================
  Seed Script - Crear Items de Prueba
============================================================

Creando 30 items de prueba...

  [1/30] Creando item... ‚úÖ Gobierno anuncia nuevas medidas...
  ...
  [30/30] Creando item... ‚úÖ Innovaci√≥n tecnol√≥gica...

============================================================
  ‚úÖ Creados: 30
  ‚ùå Fallidos: 0
============================================================
```

### Paso 7: Recargar la P√°gina de Admin

1. Ir a: http://localhost:4321/admin/scraping
2. Presionar `F5` para recargar
3. Ahora deber√≠as ver:
   - ‚úÖ Stats cargadas (tarjetas con n√∫meros)
   - ‚úÖ Tabla con 20 items
   - ‚úÖ Todo funcionando

## üêõ Si A√∫n No Funciona

### Verificaci√≥n 1: Backend est√° en el puerto correcto

```powershell
curl http://localhost:8000/health
```

Debe retornar: `{"ok":true}`

### Verificaci√≥n 2: Frontend est√° usando la URL correcta

Abrir consola del navegador (F12) y verificar que las peticiones van a:
```
http://localhost:8000/api/scraping-items/...
```

### Verificaci√≥n 3: Usuario est√° autenticado

En http://localhost:4321/admin/scraping, verificar que:
- Tienes sesi√≥n iniciada como admin
- No te redirige al login

### Verificaci√≥n 4: No hay errores en el backend

En la terminal donde corre el backend, no deber√≠a haber errores tipo:
```
ERROR: ...
```

Si ves errores, c√≥pialos y revisa.

## ‚úÖ Checklist Final

Despu√©s de reiniciar el backend:

- [ ] Backend corriendo en puerto 8000
- [ ] Swagger muestra secci√≥n "scraping-items" con 9 endpoints
- [ ] `curl http://localhost:8000/api/scraping-items/stats/summary` retorna JSON
- [ ] Tabla `scraping_items` existe en DB
- [ ] Script seed crea 30 items exitosamente
- [ ] P√°gina http://localhost:4321/admin/scraping carga sin errores
- [ ] Stats se muestran correctamente
- [ ] Tabla muestra items

## üéØ Resumen

**El problema:** El backend no ten√≠a cargadas las nuevas rutas de scraping-items.

**La soluci√≥n:** Reiniciar el backend con `uvicorn`.

**Verificaci√≥n:** Abrir http://localhost:8000/docs y buscar "scraping-items".

---

**Si sigues estos pasos, todo deber√≠a funcionar correctamente.** üöÄ
