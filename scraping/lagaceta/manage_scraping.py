"""
Script de utilidades para gestionar items de scraping
- Ver estad√≠sticas
- Mover items entre estados del pipeline
- Detectar duplicados
- Limpiar datos
"""

import asyncio
import asyncpg
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables from .env file
env_path = Path(__file__).parent / ".env"
load_dotenv(dotenv_path=env_path)

# Reconfigure stdout for Windows unicode support
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')

# Database connection
DB_CONFIG = {
    "host": os.getenv("DB_HOST", "localhost"),
    "port": int(os.getenv("DB_PORT", "5432")),
    "database": os.getenv("DB_NAME", "ladatajusta"),
    "user": os.getenv("DB_USER", "ladatajusta"),
    "password": os.getenv("DB_PASSWORD", "ladatajusta"),
}


async def show_stats(conn):
    """Muestra estad√≠sticas de scraping"""
    print("\n" + "="*60)
    print("üìä ESTAD√çSTICAS DE SCRAPING - LA GACETA")
    print("="*60)

    # Total de items
    total = await conn.fetchval(
        "SELECT COUNT(*) FROM scraping_items WHERE source_media = 'lagaceta'"
    )
    print(f"\nüì¶ Total de items: {total}")

    # Por estado
    print("\nüìà Items por estado:")
    rows = await conn.fetch(
        """
        SELECT status, COUNT(*) as count
        FROM scraping_items
        WHERE source_media = 'lagaceta'
        GROUP BY status
        ORDER BY count DESC
        """
    )
    for row in rows:
        print(f"   {row['status']:20} ‚Üí {row['count']:5} items")

    # √öltimos scrapes
    print("\nüïê √öltimos scrapes:")
    rows = await conn.fetch(
        """
        SELECT
            DATE_TRUNC('day', scraped_at) as day,
            COUNT(*) as count
        FROM scraping_items
        WHERE source_media = 'lagaceta'
        GROUP BY day
        ORDER BY day DESC
        LIMIT 7
        """
    )
    for row in rows:
        print(f"   {row['day'].strftime('%Y-%m-%d')} ‚Üí {row['count']:5} items")

    # Duplicados detectados
    duplicates = await conn.fetchval(
        """
        SELECT COUNT(DISTINCT content_hash)
        FROM scraping_items
        WHERE source_media = 'lagaceta'
        HAVING COUNT(*) > 1
        """
    )
    if duplicates:
        print(f"\n‚ö†Ô∏è Duplicados detectados: {duplicates}")

    print("\n" + "="*60)


async def list_recent(conn, limit=10):
    """Lista los items m√°s recientes"""
    print(f"\nüì∞ √öltimos {limit} items scrapeados:\n")

    rows = await conn.fetch(
        """
        SELECT
            id,
            title,
            status,
            scraped_at,
            article_date
        FROM scraping_items
        WHERE source_media = 'lagaceta'
        ORDER BY scraped_at DESC
        LIMIT $1
        """,
        limit
    )

    for i, row in enumerate(rows, 1):
        print(f"{i}. [{row['status']}] {row['title'][:60]}...")
        print(f"   Scrapeado: {row['scraped_at'].strftime('%Y-%m-%d %H:%M')}")
        if row['article_date']:
            print(f"   Publicado: {row['article_date'].strftime('%Y-%m-%d %H:%M')}")
        print()


async def mark_ready_for_ai(conn, hours_ago=24):
    """
    Marca items recientes como listos para procesamiento AI
    """
    print(f"\nü§ñ Marcando items de √∫ltimas {hours_ago} horas como 'ready_for_ai'...")

    result = await conn.execute(
        """
        UPDATE scraping_items
        SET status = 'ready_for_ai',
            status_message = 'Auto-marked by manage script'
        WHERE source_media = 'lagaceta'
          AND status = 'scraped'
          AND scraped_at >= NOW() - INTERVAL '1 hour' * $1
        """,
        hours_ago
    )

    # Extraer n√∫mero de filas afectadas
    count = int(result.split()[-1])
    print(f"‚úÖ {count} items marcados como listos para AI")


async def detect_duplicates(conn):
    """Detecta y reporta duplicados"""
    print("\nüîç Buscando duplicados por contenido...\n")

    rows = await conn.fetch(
        """
        SELECT
            content_hash,
            COUNT(*) as duplicate_count,
            array_agg(id) as item_ids,
            array_agg(title) as titles,
            MIN(scraped_at) as first_scraped,
            MAX(scraped_at) as last_scraped
        FROM scraping_items
        WHERE source_media = 'lagaceta'
        GROUP BY content_hash
        HAVING COUNT(*) > 1
        ORDER BY duplicate_count DESC
        LIMIT 10
        """
    )

    if not rows:
        print("‚úÖ No se encontraron duplicados")
        return

    for i, row in enumerate(rows, 1):
        print(f"{i}. {row['duplicate_count']} copias:")
        print(f"   T√≠tulo: {row['titles'][0][:60]}...")
        print(f"   Primera vez: {row['first_scraped'].strftime('%Y-%m-%d %H:%M')}")
        print(f"   √öltima vez: {row['last_scraped'].strftime('%Y-%m-%d %H:%M')}")
        print(f"   IDs: {', '.join(str(id)[:8] for id in row['item_ids'])}")
        print()


async def cleanup_old_errors(conn, days_ago=7):
    """
    Limpia items con error muy antiguos
    """
    print(f"\nüßπ Limpiando items con error de hace m√°s de {days_ago} d√≠as...")

    result = await conn.execute(
        """
        DELETE FROM scraping_items
        WHERE source_media = 'lagaceta'
          AND status = 'error'
          AND scraped_at < NOW() - INTERVAL '1 day' * $1
        """,
        days_ago
    )

    count = int(result.split()[-1])
    print(f"‚úÖ {count} items eliminados")


async def show_menu():
    """Muestra men√∫ interactivo"""
    print("\n" + "="*60)
    print("üîß MEN√ö DE GESTI√ìN DE SCRAPING")
    print("="*60)
    print("\n1. Ver estad√≠sticas")
    print("2. Listar items recientes (10)")
    print("3. Listar items recientes (50)")
    print("4. Marcar √∫ltimas 24h como 'ready_for_ai'")
    print("5. Detectar duplicados")
    print("6. Limpiar errores antiguos (>7 d√≠as)")
    print("7. Marcar √∫ltimas 48h como 'ready_for_ai'")
    print("0. Salir")
    print("\n" + "="*60)

    return input("Selecciona una opci√≥n: ").strip()


async def main():
    """Funci√≥n principal con men√∫ interactivo"""
    print("üöÄ Gestor de Scraping - La Gaceta")

    # Conectar a la base de datos
    try:
        conn = await asyncpg.connect(**DB_CONFIG)
        print("‚úÖ Conectado a PostgreSQL\n")
    except Exception as e:
        print(f"‚ùå Error conectando a PostgreSQL: {e}")
        return

    try:
        while True:
            opcion = await show_menu()

            if opcion == "0":
                print("\nüëã ¬°Hasta luego!")
                break
            elif opcion == "1":
                await show_stats(conn)
            elif opcion == "2":
                await list_recent(conn, 10)
            elif opcion == "3":
                await list_recent(conn, 50)
            elif opcion == "4":
                await mark_ready_for_ai(conn, 24)
            elif opcion == "5":
                await detect_duplicates(conn)
            elif opcion == "6":
                await cleanup_old_errors(conn, 7)
            elif opcion == "7":
                await mark_ready_for_ai(conn, 48)
            else:
                print("‚ùå Opci√≥n inv√°lida")

            input("\nPresiona Enter para continuar...")

    finally:
        await conn.close()
        print("\nüîå Conexi√≥n cerrada")


if __name__ == "__main__":
    asyncio.run(main())
